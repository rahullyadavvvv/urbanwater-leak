# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WeuGen8q4laoNfbZ52Bq25DcXHRqdeLH
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# Title
st.title("Urban Water Leak Prediction App 💧")
st.markdown("Upload your dataset and run Random Forest or LSTM model for prediction")

# Upload CSV
uploaded_file = st.file_uploader("Upload your dataset (input_model_potenc_predXfault7_A.csv)", type="csv")
if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.write("📊 Preview of Data:")
    st.dataframe(df.head())

    # Preprocessing
    st.subheader("1. Data Preprocessing")
    df['timestamp'] = pd.to_datetime(df['timestamp'], dayfirst=True, errors='coerce')
    df = df.dropna(subset=['timestamp'])
    df['hour'] = df['timestamp'].dt.hour
    df['dayofweek'] = df['timestamp'].dt.dayofweek
    df = df.drop(columns=['timestamp'])

    # Drop columns with >40% NaNs
    df = df.dropna(thresh=int(0.6 * len(df)), axis=1)

    # Fill missing values
    df.fillna(method='ffill', inplace=True)
    df.fillna(method='bfill', inplace=True)

    # Features and label
    X = df.drop(columns=['fault_d7'])
    y = df['fault_d7']

    # Train/test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Model selection
    model_option = st.selectbox("Select a model to train:", ["Random Forest", "LSTM"])

    if model_option == "Random Forest":
        st.subheader("2. Training Random Forest Model 🌲")
        rf = RandomForestClassifier(n_estimators=100, random_state=42)
        rf.fit(X_train_scaled, y_train)
        y_pred = rf.predict(X_test_scaled)

        acc = accuracy_score(y_test, y_pred)
        st.write(f"**Accuracy:** {acc:.4f}")
        st.text("Classification Report:")
        st.text(classification_report(y_test, y_pred))
        st.text("Confusion Matrix:")
        st.write(confusion_matrix(y_test, y_pred))

    elif model_option == "LSTM":
        st.subheader("2. Training LSTM Model 🔁")

        # Reshape for LSTM [samples, timesteps, features]
        X_train_lstm = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
        X_test_lstm = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

        model = Sequential()
        model.add(LSTM(64, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]), return_sequences=False))
        model.add(Dropout(0.2))
        model.add(Dense(1, activation='sigmoid'))

        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

        early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
        history = model.fit(
            X_train_lstm, y_train,
            validation_split=0.2,
            epochs=30,
            batch_size=64,
            callbacks=[early_stop],
            verbose=0
        )

        # Predictions
        y_pred_probs = model.predict(X_test_lstm)
        y_pred_lstm = (y_pred_probs > 0.5).astype(int)

        acc_lstm = accuracy_score(y_test, y_pred_lstm)
        st.write(f"**LSTM Accuracy:** {acc_lstm:.4f}")
        st.text("Classification Report:")
        st.text(classification_report(y_test, y_pred_lstm))
        st.text("Confusion Matrix:")
        st.write(confusion_matrix(y_test, y_pred_lstm))

        # Plot
        st.subheader("3. Accuracy & Loss Graph 📈")
        fig, ax = plt.subplots(1, 2, figsize=(14, 4))

        ax[0].plot(history.history['accuracy'], label='Train Accuracy')
        ax[0].plot(history.history['val_accuracy'], label='Val Accuracy')
        ax[0].set_title('Model Accuracy')
        ax[0].legend()

        ax[1].plot(history.history['loss'], label='Train Loss')
        ax[1].plot(history.history['val_loss'], label='Val Loss')
        ax[1].set_title('Model Loss')
        ax[1].legend()

        st.pyplot(fig)